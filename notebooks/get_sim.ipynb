{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c136f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a94c232",
   "metadata": {},
   "source": [
    "# Analyse flat results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8142e0",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac76d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CODING PATTERN ANALYSIS BY AGENT\n",
      "================================================================================\n",
      "\n",
      "Ava's Coding Pattern:\n",
      "----------------------------------------\n",
      "  WCT     : 115 times ( 51.3%)\n",
      "  NONE    :  51 times ( 22.8%)\n",
      "  GT      :  42 times ( 18.8%)\n",
      "  Other   :  16 times (  7.1%)\n",
      "\n",
      "Ben's Coding Pattern:\n",
      "----------------------------------------\n",
      "  WCT     : 152 times ( 67.9%)\n",
      "  NONE    :  41 times ( 18.3%)\n",
      "  GT      :  16 times (  7.1%)\n",
      "  Other   :  15 times (  6.7%)\n",
      "\n",
      "Cam's Coding Pattern:\n",
      "----------------------------------------\n",
      "  WCT     : 152 times ( 67.9%)\n",
      "  NONE    :  36 times ( 16.1%)\n",
      "  GT      :  22 times (  9.8%)\n",
      "  Other   :  14 times (  6.2%)\n",
      "\n",
      "================================================================================\n",
      "CODING PATTERN BY ROUND\n",
      "================================================================================\n",
      "\n",
      "Round 1:\n",
      "----------------------------------------\n",
      "  Ava: {'NONE': 20, 'Other': 5, 'WCT': 53, 'GT': 22}\n",
      "  Ben: {'GT': 8, 'WCT': 66, 'Other': 9, 'NONE': 17}\n",
      "  Cam: {'WCT': 71, 'NONE': 10, 'GT': 10, 'Other': 9}\n",
      "\n",
      "Round 2:\n",
      "----------------------------------------\n",
      "  Ava: {'NONE': 15, 'Other': 7, 'WCT': 40, 'GT': 13}\n",
      "  Ben: {'NONE': 13, 'Other': 4, 'WCT': 54, 'GT': 4}\n",
      "  Cam: {'WCT': 50, 'GT': 7, 'NONE': 16, 'Other': 2}\n",
      "\n",
      "Round 3:\n",
      "----------------------------------------\n",
      "  Ava: {'GT': 7, 'Other': 4, 'WCT': 22, 'NONE': 16}\n",
      "  Ben: {'WCT': 32, 'NONE': 11, 'GT': 4, 'Other': 2}\n",
      "  Cam: {'WCT': 31, 'Other': 3, 'GT': 5, 'NONE': 10}\n",
      "\n",
      "================================================================================\n",
      "AGREEMENT PATTERNS\n",
      "================================================================================\n",
      "all_agree           :  71 times ( 31.7%)\n",
      "ava_ben_agree       :  40 times ( 17.9%)\n",
      "ava_cam_agree       :  34 times ( 15.2%)\n",
      "ben_cam_agree       :  52 times ( 23.2%)\n",
      "all_disagree        :  27 times ( 12.1%)\n",
      "\n",
      "================================================================================\n",
      "CODE TRANSITIONS BY AGENT (Round to Round)\n",
      "================================================================================\n",
      "\n",
      "Ava's Transitions:\n",
      "  From GT:\n",
      "    → WCT: 17 times\n",
      "    → GT: 11 times\n",
      "    → NONE: 4 times\n",
      "    → Other: 1 times\n",
      "  From NONE:\n",
      "    → NONE: 18 times\n",
      "    → WCT: 13 times\n",
      "    → GT: 2 times\n",
      "    → Other: 2 times\n",
      "  From Other:\n",
      "    → Other: 5 times\n",
      "    → WCT: 5 times\n",
      "    → NONE: 1 times\n",
      "    → GT: 1 times\n",
      "  From WCT:\n",
      "    → WCT: 27 times\n",
      "    → NONE: 8 times\n",
      "    → GT: 6 times\n",
      "    → Other: 3 times\n",
      "\n",
      "Ben's Transitions:\n",
      "  From GT:\n",
      "    → WCT: 7 times\n",
      "    → NONE: 2 times\n",
      "    → GT: 1 times\n",
      "  From NONE:\n",
      "    → WCT: 18 times\n",
      "    → NONE: 10 times\n",
      "    → GT: 1 times\n",
      "    → Other: 1 times\n",
      "  From Other:\n",
      "    → WCT: 6 times\n",
      "    → Other: 3 times\n",
      "    → GT: 2 times\n",
      "    → NONE: 2 times\n",
      "  From WCT:\n",
      "    → WCT: 55 times\n",
      "    → NONE: 10 times\n",
      "    → GT: 4 times\n",
      "    → Other: 2 times\n",
      "\n",
      "Cam's Transitions:\n",
      "  From GT:\n",
      "    → WCT: 7 times\n",
      "    → GT: 5 times\n",
      "    → NONE: 2 times\n",
      "    → Other: 1 times\n",
      "  From NONE:\n",
      "    → WCT: 16 times\n",
      "    → NONE: 9 times\n",
      "    → GT: 1 times\n",
      "  From Other:\n",
      "    → WCT: 8 times\n",
      "    → NONE: 2 times\n",
      "    → GT: 1 times\n",
      "  From WCT:\n",
      "    → WCT: 50 times\n",
      "    → NONE: 13 times\n",
      "    → GT: 5 times\n",
      "    → Other: 4 times\n",
      "\n",
      "================================================================================\n",
      "STABILITY METRICS\n",
      "================================================================================\n",
      "\n",
      "Ava's Stability:\n",
      "----------------------------------------\n",
      "  GT      : 11/33 stayed same ( 33.3%)\n",
      "  NONE    : 18/35 stayed same ( 51.4%)\n",
      "  Other   : 5/12 stayed same ( 41.7%)\n",
      "  WCT     : 27/44 stayed same ( 61.4%)\n",
      "\n",
      "Ben's Stability:\n",
      "----------------------------------------\n",
      "  GT      : 1/10 stayed same ( 10.0%)\n",
      "  NONE    : 10/30 stayed same ( 33.3%)\n",
      "  Other   : 3/13 stayed same ( 23.1%)\n",
      "  WCT     : 55/71 stayed same ( 77.5%)\n",
      "\n",
      "Cam's Stability:\n",
      "----------------------------------------\n",
      "  GT      : 5/15 stayed same ( 33.3%)\n",
      "  NONE    : 9/26 stayed same ( 34.6%)\n",
      "  Other   : 0/11 stayed same (  0.0%)\n",
      "  WCT     : 50/72 stayed same ( 69.4%)\n",
      "\n",
      "================================================================================\n",
      "SIMILARITY SCORE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Average Similarity Scores:\n",
      "----------------------------------------\n",
      "  Ava_Ben   : 0.5008\n",
      "  Ava_Cam   : 0.5057\n",
      "  Ben_Cam   : 0.5433\n",
      "\n",
      "Similarity by Round:\n",
      "----------------------------------------\n",
      "\n",
      "  Round 1:\n",
      "    Ava-Ben: 0.4675\n",
      "    Ava-Cam: 0.4928\n",
      "    Ben-Cam: 0.5423\n",
      "\n",
      "  Round 2:\n",
      "    Ava-Ben: 0.5038\n",
      "    Ava-Cam: 0.5284\n",
      "    Ben-Cam: 0.5456\n",
      "\n",
      "  Round 3:\n",
      "    Ava-Ben: 0.5641\n",
      "    Ava-Cam: 0.4972\n",
      "    Ben-Cam: 0.5417\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5d59033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b450a21",
   "metadata": {},
   "source": [
    "## Agent coding visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89736c38",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "141caaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Reset any partial matplotlib imports from previous failures\n",
    "for _mod in list(sys.modules):\n",
    "    if _mod.startswith(\"matplotlib\"):\n",
    "        sys.modules.pop(_mod, None)\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\", force=True)\n",
    "fig_path = r\"C:\\Users\\bahar\\Repositories\\llm-ta-aied26\\results\\figures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1e3e0782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "\n",
    "def load_data(filepath):\n",
    "    \"\"\"Load and parse the CSV data.\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['codes_dict'] = df['codes'].apply(lambda x: eval(x))\n",
    "    return df\n",
    "\n",
    "def plot_overall_distribution(df, save_path='agent_code_distribution.png'):\n",
    "    \"\"\"Plot overall code distribution for each agent.\"\"\"\n",
    "    # Extract codes\n",
    "    all_codes = {'Ava': [], 'Ben': [], 'Cam': []}\n",
    "    for _, row in df.iterrows():\n",
    "        codes = row['codes_dict']\n",
    "        for agent, code in codes.items():\n",
    "            all_codes[agent].append(code)\n",
    "    \n",
    "    # Create data for plotting\n",
    "    code_types = ['WCT', 'NONE', 'GT', 'Other']\n",
    "    agents = ['Ava', 'Ben', 'Cam']\n",
    "    \n",
    "    data = []\n",
    "    for agent in agents:\n",
    "        counts = Counter(all_codes[agent])\n",
    "        total = len(all_codes[agent])\n",
    "        for code in code_types:\n",
    "            percentage = (counts[code] / total * 100) if code in counts else 0\n",
    "            data.append({\n",
    "                'Agent': agent,\n",
    "                'Code': code,\n",
    "                'Percentage': percentage,\n",
    "                'Count': counts.get(code, 0)\n",
    "            })\n",
    "    \n",
    "    plot_df = pd.DataFrame(data)\n",
    "    \n",
    "    # Create plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Grouped bar chart\n",
    "    x = np.arange(len(code_types))\n",
    "    width = 0.25\n",
    "    \n",
    "    for i, agent in enumerate(agents):\n",
    "        agent_data = plot_df[plot_df['Agent'] == agent]\n",
    "        percentages = [agent_data[agent_data['Code'] == code]['Percentage'].values[0] \n",
    "                      for code in code_types]\n",
    "        ax1.bar(x + i*width, percentages, width, label=agent)\n",
    "    \n",
    "    ax1.set_xlabel('Code Type', fontsize=12)\n",
    "    ax1.set_ylabel('Percentage (%)', fontsize=12)\n",
    "    ax1.set_title('Code Distribution by Agent', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xticks(x + width)\n",
    "    ax1.set_xticklabels(code_types)\n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Stacked bar chart\n",
    "    for code in code_types:\n",
    "        code_data = [plot_df[(plot_df['Agent'] == agent) & (plot_df['Code'] == code)]['Percentage'].values[0] \n",
    "                    for agent in agents]\n",
    "        ax2.bar(agents, code_data, label=code)\n",
    "    \n",
    "    ax2.set_xlabel('Agent', fontsize=12)\n",
    "    ax2.set_ylabel('Percentage (%)', fontsize=12)\n",
    "    ax2.set_title('Code Distribution (Stacked)', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(title='Code Type')\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{fig_path}/{save_path}', dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved: {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_agreement_patterns(df, save_path='agreement_patterns.png'):\n",
    "    \"\"\"Plot agreement patterns between agents.\"\"\"\n",
    "    agreement_counts = {\n",
    "        'All 3 Agree': 0,\n",
    "        'Ava & Ben': 0,\n",
    "        'Ava & Cam': 0,\n",
    "        'Ben & Cam': 0,\n",
    "        'All Disagree': 0\n",
    "    }\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        codes = row['codes_dict']\n",
    "        ava, ben, cam = codes['Ava'], codes['Ben'], codes['Cam']\n",
    "    \n",
    "        if ava == ben == cam:\n",
    "            agreement_counts['All 3 Agree'] += 1\n",
    "        elif ava == ben:\n",
    "            agreement_counts['Ava & Ben'] += 1\n",
    "        elif ava == cam:\n",
    "            agreement_counts['Ava & Cam'] += 1\n",
    "        elif ben == cam:\n",
    "            agreement_counts['Ben & Cam'] += 1\n",
    "        else:\n",
    "            agreement_counts['All Disagree'] += 1\n",
    "    \n",
    "    total = len(df)\n",
    "    \n",
    "    # Create pie chart\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Pie chart\n",
    "    colors = ['#2ecc71', '#3498db', '#9b59b6', '#e74c3c', '#95a5a6']\n",
    "    wedges, texts, autotexts = ax1.pie(\n",
    "        agreement_counts.values(),\n",
    "        labels=agreement_counts.keys(),\n",
    "        autopct='%1.1f%%',\n",
    "        colors=colors,\n",
    "        startangle=90\n",
    "    )\n",
    "    ax1.set_title('Agreement Pattern Distribution', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Make percentage text more readable\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "        autotext.set_fontweight('bold')\n",
    "    \n",
    "    # Bar chart\n",
    "    ax2.barh(list(agreement_counts.keys()), list(agreement_counts.values()), color=colors)\n",
    "    ax2.set_xlabel('Count', fontsize=12)\n",
    "    ax2.set_title('Agreement Pattern Counts', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, v in enumerate(agreement_counts.values()):\n",
    "        ax2.text(v + 1, i, str(v), va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{fig_path}/{save_path}', dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved: {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_round_evolution(df, save_path='round_evolution.png'):\n",
    "    \"\"\"Plot how coding patterns evolve across rounds.\"\"\"\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "    agents = ['Ava', 'Ben', 'Cam']\n",
    "    code_types = ['WCT', 'NONE', 'GT', 'Other']\n",
    "    colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']\n",
    "    \n",
    "    for idx, agent in enumerate(agents):\n",
    "        ax = axes[idx]\n",
    "    \n",
    "        for code, color in zip(code_types, colors):\n",
    "            round_percentages = []\n",
    "            for round_num in sorted(df['round'].unique()):\n",
    "                round_df = df[df['round'] == round_num]\n",
    "                codes = [row['codes_dict'][agent] for _, row in round_df.iterrows()]\n",
    "                count = codes.count(code)\n",
    "                percentage = (count / len(codes) * 100) if codes else 0\n",
    "                round_percentages.append(percentage)\n",
    "    \n",
    "            ax.plot(sorted(df['round'].unique()), round_percentages, \n",
    "                   marker='o', linewidth=2, label=code, color=color)\n",
    "    \n",
    "        ax.set_xlabel('Round', fontsize=11)\n",
    "        ax.set_ylabel('Percentage (%)', fontsize=11)\n",
    "        ax.set_title(f'{agent}\\'s Coding Evolution Across Rounds', \n",
    "                    fontsize=13, fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_xticks(sorted(df['round'].unique()))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path_full = os.path.join(fig_path, save_path)\n",
    "    plt.savefig(save_path_full, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved: {save_path_full}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_similarity_heatmap(df, save_path='similarity_heatmap.png'):\n",
    "    \"\"\"Plot similarity scores as heatmap across rounds (matplotlib fallback).\"\"\"\n",
    "    rounds = sorted(df['round'].unique())\n",
    "    if not rounds:\n",
    "        print(\"No rounds found for similarity heatmap.\")\n",
    "        return\n",
    "    \n",
    "    similarity_data = {\n",
    "        'Ava-Ben': [],\n",
    "        'Ava-Cam': [],\n",
    "        'Ben-Cam': []\n",
    "    }\n",
    "    for round_num in rounds:\n",
    "        round_df = df[df['round'] == round_num]\n",
    "        similarity_data['Ava-Ben'].append(round_df['sim_Ava_Ben'].mean())\n",
    "        similarity_data['Ava-Cam'].append(round_df['sim_Ava_Cam'].mean())\n",
    "        similarity_data['Ben-Cam'].append(round_df['sim_Ben_Cam'].mean())\n",
    "    \n",
    "    heatmap_data = pd.DataFrame(similarity_data, index=[f'Round {r}' for r in rounds])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    im = ax.imshow(heatmap_data.T.values, aspect='auto', cmap='YlGnBu')\n",
    "    ax.set_yticks(range(len(heatmap_data.columns)))\n",
    "    ax.set_yticklabels(heatmap_data.columns)\n",
    "    ax.set_xticks(range(len(heatmap_data.index)))\n",
    "    ax.set_xticklabels(heatmap_data.index, rotation=45, ha='right')\n",
    "    ax.set_title('Agent Similarity Scores Across Rounds', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Round', fontsize=12)\n",
    "    ax.set_ylabel('Agent Pair', fontsize=12)\n",
    "    fig.colorbar(im, ax=ax, label='Similarity Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path_full = os.path.join(fig_path, save_path)\n",
    "    plt.savefig(save_path_full, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved: {save_path_full}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_transition_sankey(df, save_path='transition_flows.png'):\n",
    "    \"\"\"Plot transition patterns for each agent (matplotlib fallback).\"\"\"\n",
    "    agents = ['Ava', 'Ben', 'Cam']\n",
    "    code_types = ['WCT', 'NONE', 'GT', 'Other']\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "    \n",
    "    for idx, agent in enumerate(agents):\n",
    "        ax = axes[idx]\n",
    "        transitions = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "        # Calculate transitions\n",
    "        for row_idx in df['row_index'].unique():\n",
    "            row_data = df[df['row_index'] == row_idx].sort_values('round')\n",
    "            codes = [row['codes_dict'][agent] for _, row in row_data.iterrows()]\n",
    "    \n",
    "            for i in range(len(codes) - 1):\n",
    "                transitions[codes[i]][codes[i+1]] += 1\n",
    "    \n",
    "        matrix = np.zeros((len(code_types), len(code_types)))\n",
    "        for i, from_code in enumerate(code_types):\n",
    "            for j, to_code in enumerate(code_types):\n",
    "                matrix[i][j] = transitions[from_code].get(to_code, 0)\n",
    "    \n",
    "        im = ax.imshow(matrix, cmap='Blues')\n",
    "        ax.set_xticks(range(len(code_types)))\n",
    "        ax.set_yticks(range(len(code_types)))\n",
    "        ax.set_xticklabels(code_types)\n",
    "        ax.set_yticklabels(code_types)\n",
    "        ax.set_title(f\"{agent}'s Code Transitions\", fontsize=13, fontweight='bold')\n",
    "        ax.set_xlabel('To Code', fontsize=11)\n",
    "        ax.set_ylabel('From Code', fontsize=11)\n",
    "        for i in range(len(code_types)):\n",
    "            for j in range(len(code_types)):\n",
    "                ax.text(j, i, int(matrix[i, j]), ha='center', va='center', color='black')\n",
    "    \n",
    "    fig.colorbar(im, ax=axes, label='Transition Count')\n",
    "    plt.tight_layout()\n",
    "    save_path_full = os.path.join(fig_path, save_path)\n",
    "    plt.savefig(save_path_full, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved: {save_path_full}\")\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "58948b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similarity_heatmap(df, save_path='similarity_heatmap.png'):\n",
    "    \"\"\"Plot similarity scores as heatmap across rounds (matplotlib fallback).\"\"\"\n",
    "    rounds = sorted(df['round'].unique())\n",
    "    if not rounds:\n",
    "        print(\"No rounds found for similarity heatmap.\")\n",
    "        return\n",
    "\n",
    "    similarity_data = {\n",
    "        'Ava-Ben': [],\n",
    "        'Ava-Cam': [],\n",
    "        'Ben-Cam': []\n",
    "    }\n",
    "    for round_num in rounds:\n",
    "        round_df = df[df['round'] == round_num]\n",
    "        similarity_data['Ava-Ben'].append(round_df['sim_Ava_Ben'].mean())\n",
    "        similarity_data['Ava-Cam'].append(round_df['sim_Ava_Cam'].mean())\n",
    "        similarity_data['Ben-Cam'].append(round_df['sim_Ben_Cam'].mean())\n",
    "\n",
    "    heatmap_data = pd.DataFrame(similarity_data, index=[f'Round {r}' for r in rounds])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    im = ax.imshow(heatmap_data.T.values, aspect='auto', cmap='YlGnBu')\n",
    "    ax.set_yticks(range(len(heatmap_data.columns)))\n",
    "    ax.set_yticklabels(heatmap_data.columns)\n",
    "    ax.set_xticks(range(len(heatmap_data.index)))\n",
    "    ax.set_xticklabels(heatmap_data.index, rotation=45, ha='right')\n",
    "    ax.set_title('Agent Similarity Scores Across Rounds', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Round', fontsize=12)\n",
    "    ax.set_ylabel('Agent Pair', fontsize=12)\n",
    "    fig.colorbar(im, ax=ax, label='Similarity Score')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{res_csv_path}/{save_path}', dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ca8cc",
   "metadata": {},
   "source": [
    "### Generate all visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0dc6a2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Generating visualizations for 224 coding instances...\n",
      "\n",
      "Saved: agent_code_distribution.png\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "\n",
    "\n",
    "print(f\"\\nGenerating visualizations for {len(flat_df)} coding instances...\\n\")\n",
    "\n",
    "plot_overall_distribution(flat_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "df96b7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bahar\\AppData\\Local\\Temp\\ipykernel_25400\\1833150010.py:253: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\bahar\\Repositories\\llm-ta-aied26\\results\\figures\\transition_flows.png\n"
     ]
    }
   ],
   "source": [
    "# plot_agreement_patterns(flat_df)\n",
    "# plot_round_evolution(flat_df)\n",
    "# plot_similarity_heatmap(flat_df)\n",
    "plot_transition_sankey(flat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b26f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96fc8d62",
   "metadata": {},
   "source": [
    "# Analysis todo\n",
    "* [x] labeling accuracy\n",
    "* [x] Extract reasoning traces\n",
    "* [x] Text embedding\n",
    "  * sentence embedding\n",
    "* [ ] semantic similarity\n",
    "  * [x] cosine sim\n",
    "  * [ ] [future] LLM Comparator\n",
    "  * [ ] [future] Self-Correction Monitoring: compare an agent's thinking in Round \\(N\\) vs Round \\(N+1\\) to see if it specifically references previous failures—a sign of high-quality \"Reflect\" patternsdentify Divergence\n",
    "* [x] Export results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1a0c6a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 12.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "res_csv_path = r\"C:\\Users\\bahar\\Repositories\\llm-ta-aied26\\results\"\n",
    "df = pd.read_csv(os.path.join(res_csv_path, \"2026-01-21-batch_0-100_results.csv\"))\n",
    "\n",
    "df.drop(columns=[\"Unnamed: 0\", \"error\"], inplace=True)\n",
    "df[\"is_correct\"] = df[\"final_code\"] == df[\"human_code\"]\n",
    "accuracy = df[\"is_correct\"].mean()\n",
    "print(f\"Overall Accuracy: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd24608e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bahar\\anaconda3\\envs\\whisperx\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dcfe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReasoningAlignmentAnalyzer:\n",
    "    \"\"\"Analyzes reasoning alignment between multiple agents in multi-round discussions\"\"\"\n",
    "\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        \"\"\"\n",
    "        Initialize with a sentence transformer model\n",
    "        Options: 'all-MiniLM-L6-v2' (fast), 'all-mpnet-base-v2' (better quality)\n",
    "        \"\"\"\n",
    "        print(f\"Loading embedding model: {model_name}\")\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.results = []\n",
    "\n",
    "    def load_discussion_data(self, discussions):\n",
    "        \"\"\"\n",
    "        Load discussion data from list of round dictionaries\n",
    "\n",
    "        Args:\n",
    "            discussions: List of dicts with format:\n",
    "                [{\n",
    "                    'row_index': '210',\n",
    "                    'text_to_code': 'text...',\n",
    "                    'human_code': 'WCT',\n",
    "                    'rounds': [\n",
    "                        {\n",
    "                            'round_num': 1,\n",
    "                            'votes': {'NONE': 1, 'GT': 1, 'WCT': 1},\n",
    "                            'responses': [\n",
    "                                {'agent': 'Ava', 'code': 'NONE', 'rationale': '...', 'raw':'..'},\n",
    "                                {'agent': 'Ben', 'code': 'GT', 'rationale': '...', 'raw':'..'},\n",
    "                                {'agent': 'Cam', 'code': 'WCT', 'rationale': '...', 'raw':'..'}\n",
    "                            ]\n",
    "                        }\n",
    "                    ]\n",
    "                }]\n",
    "        \"\"\"\n",
    "        self.discussions = discussions\n",
    "        print(f\"Loaded {len(discussions)} discussion segments\")\n",
    "\n",
    "    def compute_pairwise_similarity(self, rationales_dict):\n",
    "        \"\"\"\n",
    "        Compute semantic similarity for all agent pairs\n",
    "\n",
    "        Args:\n",
    "            rationales_dict: {'Ava': 'rationale1', 'Ben': 'rationale2', 'Cam': 'rationale3'}\n",
    "\n",
    "        Returns:\n",
    "            dict: {('Ava', 'Ben'): 0.85, ('Ava', 'Cam'): 0.72, ('Ben', 'Cam'): 0.68}\n",
    "        \"\"\"\n",
    "        agents = list(rationales_dict.keys())\n",
    "        rationales = [rationales_dict[agent] for agent in agents]\n",
    "\n",
    "        # Generate embeddings\n",
    "        embeddings = self.model.encode(rationales)\n",
    "\n",
    "        # Compute pairwise similarities\n",
    "        similarities = {}\n",
    "        for i, j in combinations(range(len(agents)), 2):\n",
    "            pair = tuple(sorted([agents[i], agents[j]]))\n",
    "            sim = cosine_similarity([embeddings[i]], [embeddings[j]])[0][0]\n",
    "            similarities[pair] = float(sim)\n",
    "\n",
    "        return similarities\n",
    "\n",
    "    def analyze_divergence_causes(self, segment_id, round_num, responses, transcript):\n",
    "        \"\"\"\n",
    "        Analyze what causes reasoning divergence using keyword extraction\n",
    "\n",
    "        Args:\n",
    "            segment_id: identifier for the segment\n",
    "            round_num: which round\n",
    "            responses: list of agent responses\n",
    "            transcript: the original teacher transcript\n",
    "\n",
    "        Returns:\n",
    "            dict: analysis of divergence causes\n",
    "        \"\"\"\n",
    "        rationales = [r['rationale'] for r in responses]\n",
    "        codes = [r['code'] for r in responses]\n",
    "        agents = [r['agent'] for r in responses]\n",
    "\n",
    "        # Check if there's disagreement\n",
    "        unique_codes = set(codes)\n",
    "        has_disagreement = len(unique_codes) > 1\n",
    "\n",
    "        if not has_disagreement:\n",
    "            return {\n",
    "                'has_disagreement': False,\n",
    "                'unique_keywords': [],\n",
    "                'shared_keywords': []\n",
    "            }\n",
    "\n",
    "        # Extract keywords from each rationale using TF-IDF\n",
    "        vectorizer = TfidfVectorizer(max_features=10, stop_words='english', ngram_range=(1, 2))\n",
    "\n",
    "        try:\n",
    "            tfidf_matrix = vectorizer.fit_transform(rationales)\n",
    "            feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "            # Get top keywords for each agent\n",
    "            agent_keywords = {}\n",
    "            for idx, agent in enumerate(agents):\n",
    "                scores = tfidf_matrix[idx].toarray()[0]\n",
    "                top_indices = scores.argsort()[-5:][::-1]\n",
    "                agent_keywords[agent] = [feature_names[i] for i in top_indices if scores[i] > 0]\n",
    "\n",
    "            # Find unique vs shared keywords\n",
    "            all_keywords = set()\n",
    "            for keywords in agent_keywords.values():\n",
    "                all_keywords.update(keywords)\n",
    "\n",
    "            # Keywords mentioned by only one agent (divergence indicators)\n",
    "            unique_keywords = []\n",
    "            for agent, keywords in agent_keywords.items():\n",
    "                unique = set(keywords) - set().union(*[set(agent_keywords[a]) for a in agents if a != agent])\n",
    "                if unique:\n",
    "                    unique_keywords.append({\n",
    "                        'agent': agent,\n",
    "                        'code': codes[agents.index(agent)],\n",
    "                        'unique_terms': list(unique)\n",
    "                    })\n",
    "\n",
    "            # Keywords shared by multiple agents\n",
    "            shared_keywords = []\n",
    "            for kw in all_keywords:\n",
    "                mentioning_agents = [a for a, kws in agent_keywords.items() if kw in kws]\n",
    "                if len(mentioning_agents) > 1:\n",
    "                    shared_keywords.append({\n",
    "                        'term': kw,\n",
    "                        'agents': mentioning_agents\n",
    "                    })\n",
    "\n",
    "            return {\n",
    "                'has_disagreement': True,\n",
    "                'disagreement_pattern': dict(zip(agents, codes)),\n",
    "                'unique_keywords': unique_keywords,\n",
    "                'shared_keywords': shared_keywords,\n",
    "                'agent_keywords': agent_keywords\n",
    "            }\n",
    "        except:\n",
    "            return {\n",
    "                'has_disagreement': True,\n",
    "                'unique_keywords': [],\n",
    "                'shared_keywords': []\n",
    "            }\n",
    "\n",
    "    def analyze_all_rounds(self):\n",
    "        \"\"\"Analyze all discussion rounds and compute metrics\"\"\"\n",
    "\n",
    "        for discussion in self.discussions:\n",
    "            segment_id = discussion['row_index']\n",
    "            transcript = discussion.get('text_to_code', '')\n",
    "            correct_code = discussion.get('human_code', None)\n",
    "\n",
    "            for round_data in discussion['rounds']:\n",
    "                round_num = round_data['round_num']\n",
    "                responses = round_data['responses']\n",
    "\n",
    "                # Build rationales dict\n",
    "                rationales_dict = {r['agent']: r['rationale'] for r in responses}\n",
    "                codes_dict = {r['agent']: r['code'] for r in responses}\n",
    "\n",
    "                # Compute pairwise similarities\n",
    "                similarities = self.compute_pairwise_similarity(rationales_dict)\n",
    "\n",
    "                # Analyze divergence causes\n",
    "                divergence = self.analyze_divergence_causes(\n",
    "                    segment_id, round_num, responses, transcript\n",
    "                )\n",
    "\n",
    "                # Store results\n",
    "                result = {\n",
    "                    'row_index': segment_id,\n",
    "                    'round': round_num,\n",
    "                    'codes': codes_dict,\n",
    "                    'has_disagreement': divergence['has_disagreement'],\n",
    "                    'similarities': similarities,\n",
    "                    'divergence_analysis': divergence,\n",
    "                    'correct_code': correct_code\n",
    "                }\n",
    "\n",
    "                # Add individual similarity scores\n",
    "                for pair, sim in similarities.items():\n",
    "                    result[f\"sim_{pair[0]}_{pair[1]}\"] = sim\n",
    "\n",
    "                self.results.append(result)\n",
    "\n",
    "        return pd.DataFrame(self.results)\n",
    "\n",
    "    def get_disagreement_patterns(self, df):\n",
    "        \"\"\"Extract patterns from disagreement cases\"\"\"\n",
    "\n",
    "        disagreements = df[df['has_disagreement'] == True]\n",
    "\n",
    "        print(f\"\\n=== DISAGREEMENT ANALYSIS ===\")\n",
    "        print(f\"Total rounds: {len(df)}\")\n",
    "        print(f\"Rounds with disagreement: {len(disagreements)} ({len(disagreements)/len(df)*100:.1f}%)\")\n",
    "\n",
    "        # Average similarity when disagreeing\n",
    "        sim_cols = [col for col in df.columns if col.startswith('sim_')]\n",
    "\n",
    "        print(f\"\\n=== AVERAGE SEMANTIC SIMILARITY ===\")\n",
    "        print(f\"When agents agree on code:\")\n",
    "        for col in sim_cols:\n",
    "            avg_agree = df[df['has_disagreement'] == False][col].mean()\n",
    "            print(f\"  {col}: {avg_agree:.3f}\")\n",
    "\n",
    "        print(f\"\\nWhen agents DISAGREE on code:\")\n",
    "        for col in sim_cols:\n",
    "            avg_disagree = df[df['has_disagreement'] == True][col].mean()\n",
    "            print(f\"  {col}: {avg_disagree:.3f}\")\n",
    "\n",
    "        # Most common disagreement patterns\n",
    "        print(f\"\\n=== COMMON DISAGREEMENT PATTERNS ===\")\n",
    "        disagreement_patterns = disagreements['divergence_analysis'].apply(\n",
    "            lambda x: tuple(sorted(x.get('disagreement_pattern', {}).values())) if x.get('disagreement_pattern') else None\n",
    "        )\n",
    "        pattern_counts = disagreement_patterns.value_counts().head(5)\n",
    "        for pattern, count in pattern_counts.items():\n",
    "            print(f\"  {pattern}: {count} times\")\n",
    "\n",
    "        return disagreements\n",
    "\n",
    "    def visualize_similarities(self, df):\n",
    "        \"\"\"Create visualizations of reasoning alignment\"\"\"\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "        # 1. Similarity distribution\n",
    "        sim_cols = [col for col in df.columns if col.startswith('sim_')]\n",
    "        ax = axes[0, 0]\n",
    "        df[sim_cols].boxplot(ax=ax)\n",
    "        ax.set_title('Distribution of Pairwise Semantic Similarities')\n",
    "        ax.set_ylabel('Cosine Similarity')\n",
    "        ax.set_xticklabels([col.replace('sim_', '') for col in sim_cols], rotation=45)\n",
    "        ax.axhline(y=0.7, color='r', linestyle='--', alpha=0.5, label='High similarity threshold')\n",
    "        ax.legend()\n",
    "\n",
    "        # 2. Similarity vs Agreement\n",
    "        ax = axes[0, 1]\n",
    "        for col in sim_cols:\n",
    "            agree = df[df['has_disagreement'] == False][col]\n",
    "            disagree = df[df['has_disagreement'] == True][col]\n",
    "\n",
    "            ax.scatter([col.replace('sim_', '')] * len(agree), agree,\n",
    "                      alpha=0.5, label='Agreement' if col == sim_cols[0] else '', color='green')\n",
    "            ax.scatter([col.replace('sim_', '')] * len(disagree), disagree,\n",
    "                      alpha=0.5, label='Disagreement' if col == sim_cols[0] else '', color='red')\n",
    "\n",
    "        ax.set_title('Similarity Scores: Agreement vs Disagreement')\n",
    "        ax.set_ylabel('Cosine Similarity')\n",
    "        ax.set_xlabel('Agent Pairs')\n",
    "        ax.legend()\n",
    "        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "        # 3. Similarity across rounds\n",
    "        ax = axes[1, 0]\n",
    "        for col in sim_cols:\n",
    "            rounds_avg = df.groupby('round')[col].mean()\n",
    "            ax.plot(rounds_avg.index, rounds_avg.values, marker='o', label=col.replace('sim_', ''))\n",
    "\n",
    "        ax.set_title('Average Similarity Across Discussion Rounds')\n",
    "        ax.set_xlabel('Round Number')\n",
    "        ax.set_ylabel('Average Cosine Similarity')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # 4. Disagreement rate by round\n",
    "        ax = axes[1, 1]\n",
    "        disagreement_by_round = df.groupby('round')['has_disagreement'].mean()\n",
    "        ax.bar(disagreement_by_round.index, disagreement_by_round.values, color='coral')\n",
    "        ax.set_title('Disagreement Rate by Round')\n",
    "        ax.set_xlabel('Round Number')\n",
    "        ax.set_ylabel('Proportion of Disagreements')\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def export_for_llm_comparator(self, output_path='llm_comparator_input.jsonl'):\n",
    "        \"\"\"\n",
    "        Export data in format for LLM Comparator tool\n",
    "        Creates pairwise comparisons for each disagreement case\n",
    "        \"\"\"\n",
    "\n",
    "        comparisons = []\n",
    "\n",
    "        for result in self.results:\n",
    "            if not result['has_disagreement']:\n",
    "                continue\n",
    "\n",
    "            segment_id = result['segment_id']\n",
    "            round_num = result['round']\n",
    "            codes = result['codes']\n",
    "\n",
    "            # Get rationales for each agent\n",
    "            discussion = next(d for d in self.discussions if d['segment_id'] == segment_id)\n",
    "            round_data = next(r for r in discussion['rounds'] if r['round_num'] == round_num)\n",
    "\n",
    "            rationales = {r['agent']: r['rationale'] for r in round_data['responses']}\n",
    "            transcript = discussion.get('transcript', '')\n",
    "\n",
    "            # Create pairwise comparisons\n",
    "            agents = list(rationales.keys())\n",
    "            for i, j in combinations(range(len(agents)), 2):\n",
    "                agent_a, agent_b = agents[i], agents[j]\n",
    "\n",
    "                comparison = {\n",
    "                    'prompt': f\"Teacher transcript: {transcript}\\n\\nTask: Assign CAD code (WCT/GT/Other)\",\n",
    "                    'response_a': {\n",
    "                        'agent': agent_a,\n",
    "                        'code': codes[agent_a],\n",
    "                        'rationale': rationales[agent_a]\n",
    "                    },\n",
    "                    'response_b': {\n",
    "                        'agent': agent_b,\n",
    "                        'code': codes[agent_b],\n",
    "                        'rationale': rationales[agent_b]\n",
    "                    },\n",
    "                    'metadata': {\n",
    "                        'segment_id': segment_id,\n",
    "                        'round': round_num,\n",
    "                        'similarity_score': result['similarities'].get(tuple(sorted([agent_a, agent_b])), None),\n",
    "                        'correct_code': result.get('correct_code')\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                comparisons.append(comparison)\n",
    "\n",
    "        # Save to JSONL\n",
    "        with open(output_path, 'w') as f:\n",
    "            for comp in comparisons:\n",
    "                f.write(json.dumps(comp) + '\\n')\n",
    "\n",
    "        print(f\"\\nExported {len(comparisons)} pairwise comparisons to {output_path}\")\n",
    "        print(f\"This file can be imported into LLM Comparator for side-by-side analysis\")\n",
    "\n",
    "        return comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4e925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Loaded 100 discussion segments\n"
     ]
    }
   ],
   "source": [
    "discussions = []\n",
    "sample = df[:100]\n",
    "for index, row in sample.iterrows():\n",
    "    row_index = row['row_index']\n",
    "    text_to_code = row['text_to_code']\n",
    "    human_code = row['human_code']\n",
    "    final_code = row['final_code']\n",
    "    is_correct = row['is_correct']\n",
    "    # rounds is a list of dicts. Each dict contains the discussion per round \n",
    "    # with keys ['round_num', 'votes', 'responses']\n",
    "    rounds = eval(row[\"round_dicts\"])\n",
    "    discussions.append({\n",
    "        'row_index': row_index,\n",
    "        'text_to_code': text_to_code,\n",
    "        'human_code': human_code,\n",
    "        'final_code': final_code,\n",
    "        'is_correct': is_correct,\n",
    "        'rounds': rounds\n",
    "    })\n",
    "\n",
    "# discussions[0][\"rounds\"][0]\n",
    "\n",
    "analyzer = ReasoningAlignmentAnalyzer()\n",
    "analyzer.load_discussion_data(discussions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d90c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>round</th>\n",
       "      <th>codes</th>\n",
       "      <th>has_disagreement</th>\n",
       "      <th>similarities</th>\n",
       "      <th>divergence_analysis</th>\n",
       "      <th>correct_code</th>\n",
       "      <th>sim_Ava_Ben</th>\n",
       "      <th>sim_Ava_Cam</th>\n",
       "      <th>sim_Ben_Cam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Ava': 'NONE', 'Ben': 'GT', 'Cam': 'WCT'}</td>\n",
       "      <td>True</td>\n",
       "      <td>{('Ava', 'Ben'): 0.5158841013908386, ('Ava', '...</td>\n",
       "      <td>{'has_disagreement': True, 'disagreement_patte...</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.515884</td>\n",
       "      <td>0.334956</td>\n",
       "      <td>0.308268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210</td>\n",
       "      <td>2</td>\n",
       "      <td>{'Ava': 'NONE', 'Ben': 'NONE', 'Cam': 'WCT'}</td>\n",
       "      <td>True</td>\n",
       "      <td>{('Ava', 'Ben'): 0.7922996282577515, ('Ava', '...</td>\n",
       "      <td>{'has_disagreement': True, 'disagreement_patte...</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.792300</td>\n",
       "      <td>0.064016</td>\n",
       "      <td>0.065549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210</td>\n",
       "      <td>3</td>\n",
       "      <td>{'Ava': 'GT', 'Ben': 'WCT', 'Cam': 'WCT'}</td>\n",
       "      <td>True</td>\n",
       "      <td>{('Ava', 'Ben'): 0.4902516305446625, ('Ava', '...</td>\n",
       "      <td>{'has_disagreement': True, 'disagreement_patte...</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.490252</td>\n",
       "      <td>0.232670</td>\n",
       "      <td>0.495799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Ava': 'Other', 'Ben': 'WCT', 'Cam': 'WCT'}</td>\n",
       "      <td>True</td>\n",
       "      <td>{('Ava', 'Ben'): 0.31579354405403137, ('Ava', ...</td>\n",
       "      <td>{'has_disagreement': True, 'disagreement_patte...</td>\n",
       "      <td>WCT</td>\n",
       "      <td>0.315794</td>\n",
       "      <td>0.315794</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211</td>\n",
       "      <td>2</td>\n",
       "      <td>{'Ava': 'Other', 'Ben': 'Other', 'Cam': 'WCT'}</td>\n",
       "      <td>True</td>\n",
       "      <td>{('Ava', 'Ben'): 0.791540265083313, ('Ava', 'C...</td>\n",
       "      <td>{'has_disagreement': True, 'disagreement_patte...</td>\n",
       "      <td>WCT</td>\n",
       "      <td>0.791540</td>\n",
       "      <td>0.276261</td>\n",
       "      <td>0.315794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>307</td>\n",
       "      <td>3</td>\n",
       "      <td>{'Ava': 'NONE', 'Ben': 'WCT', 'Cam': 'NONE'}</td>\n",
       "      <td>True</td>\n",
       "      <td>{('Ava', 'Ben'): 0.3151782751083374, ('Ava', '...</td>\n",
       "      <td>{'has_disagreement': True, 'disagreement_patte...</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.315178</td>\n",
       "      <td>0.937626</td>\n",
       "      <td>0.231563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>308</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Ava': 'WCT', 'Ben': 'GT', 'Cam': 'WCT'}</td>\n",
       "      <td>True</td>\n",
       "      <td>{('Ava', 'Ben'): 0.5765784382820129, ('Ava', '...</td>\n",
       "      <td>{'has_disagreement': True, 'disagreement_patte...</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.576578</td>\n",
       "      <td>0.370572</td>\n",
       "      <td>0.353177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>308</td>\n",
       "      <td>2</td>\n",
       "      <td>{'Ava': 'WCT', 'Ben': 'WCT', 'Cam': 'WCT'}</td>\n",
       "      <td>False</td>\n",
       "      <td>{('Ava', 'Ben'): 0.6275327205657959, ('Ava', '...</td>\n",
       "      <td>{'has_disagreement': False, 'unique_keywords':...</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.627533</td>\n",
       "      <td>0.727612</td>\n",
       "      <td>0.852188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>309</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Ava': 'GT', 'Ben': 'WCT', 'Cam': 'WCT'}</td>\n",
       "      <td>True</td>\n",
       "      <td>{('Ava', 'Ben'): 0.4568682312965393, ('Ava', '...</td>\n",
       "      <td>{'has_disagreement': True, 'disagreement_patte...</td>\n",
       "      <td>GT</td>\n",
       "      <td>0.456868</td>\n",
       "      <td>0.239602</td>\n",
       "      <td>0.277179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>309</td>\n",
       "      <td>2</td>\n",
       "      <td>{'Ava': 'WCT', 'Ben': 'WCT', 'Cam': 'WCT'}</td>\n",
       "      <td>False</td>\n",
       "      <td>{('Ava', 'Ben'): 0.3003937602043152, ('Ava', '...</td>\n",
       "      <td>{'has_disagreement': False, 'unique_keywords':...</td>\n",
       "      <td>GT</td>\n",
       "      <td>0.300394</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_index  round                                           codes  \\\n",
       "0          210      1      {'Ava': 'NONE', 'Ben': 'GT', 'Cam': 'WCT'}   \n",
       "1          210      2    {'Ava': 'NONE', 'Ben': 'NONE', 'Cam': 'WCT'}   \n",
       "2          210      3       {'Ava': 'GT', 'Ben': 'WCT', 'Cam': 'WCT'}   \n",
       "3          211      1    {'Ava': 'Other', 'Ben': 'WCT', 'Cam': 'WCT'}   \n",
       "4          211      2  {'Ava': 'Other', 'Ben': 'Other', 'Cam': 'WCT'}   \n",
       "..         ...    ...                                             ...   \n",
       "219        307      3    {'Ava': 'NONE', 'Ben': 'WCT', 'Cam': 'NONE'}   \n",
       "220        308      1       {'Ava': 'WCT', 'Ben': 'GT', 'Cam': 'WCT'}   \n",
       "221        308      2      {'Ava': 'WCT', 'Ben': 'WCT', 'Cam': 'WCT'}   \n",
       "222        309      1       {'Ava': 'GT', 'Ben': 'WCT', 'Cam': 'WCT'}   \n",
       "223        309      2      {'Ava': 'WCT', 'Ben': 'WCT', 'Cam': 'WCT'}   \n",
       "\n",
       "     has_disagreement                                       similarities  \\\n",
       "0                True  {('Ava', 'Ben'): 0.5158841013908386, ('Ava', '...   \n",
       "1                True  {('Ava', 'Ben'): 0.7922996282577515, ('Ava', '...   \n",
       "2                True  {('Ava', 'Ben'): 0.4902516305446625, ('Ava', '...   \n",
       "3                True  {('Ava', 'Ben'): 0.31579354405403137, ('Ava', ...   \n",
       "4                True  {('Ava', 'Ben'): 0.791540265083313, ('Ava', 'C...   \n",
       "..                ...                                                ...   \n",
       "219              True  {('Ava', 'Ben'): 0.3151782751083374, ('Ava', '...   \n",
       "220              True  {('Ava', 'Ben'): 0.5765784382820129, ('Ava', '...   \n",
       "221             False  {('Ava', 'Ben'): 0.6275327205657959, ('Ava', '...   \n",
       "222              True  {('Ava', 'Ben'): 0.4568682312965393, ('Ava', '...   \n",
       "223             False  {('Ava', 'Ben'): 0.3003937602043152, ('Ava', '...   \n",
       "\n",
       "                                   divergence_analysis correct_code  \\\n",
       "0    {'has_disagreement': True, 'disagreement_patte...        Other   \n",
       "1    {'has_disagreement': True, 'disagreement_patte...        Other   \n",
       "2    {'has_disagreement': True, 'disagreement_patte...        Other   \n",
       "3    {'has_disagreement': True, 'disagreement_patte...          WCT   \n",
       "4    {'has_disagreement': True, 'disagreement_patte...          WCT   \n",
       "..                                                 ...          ...   \n",
       "219  {'has_disagreement': True, 'disagreement_patte...        Other   \n",
       "220  {'has_disagreement': True, 'disagreement_patte...        Other   \n",
       "221  {'has_disagreement': False, 'unique_keywords':...        Other   \n",
       "222  {'has_disagreement': True, 'disagreement_patte...           GT   \n",
       "223  {'has_disagreement': False, 'unique_keywords':...           GT   \n",
       "\n",
       "     sim_Ava_Ben  sim_Ava_Cam  sim_Ben_Cam  \n",
       "0       0.515884     0.334956     0.308268  \n",
       "1       0.792300     0.064016     0.065549  \n",
       "2       0.490252     0.232670     0.495799  \n",
       "3       0.315794     0.315794     1.000000  \n",
       "4       0.791540     0.276261     0.315794  \n",
       "..           ...          ...          ...  \n",
       "219     0.315178     0.937626     0.231563  \n",
       "220     0.576578     0.370572     0.353177  \n",
       "221     0.627533     0.727612     0.852188  \n",
       "222     0.456868     0.239602     0.277179  \n",
       "223     0.300394     1.000000     0.300394  \n",
       "\n",
       "[224 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results_df = analyzer.analyze_all_rounds()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa48930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(r\"C:\\Users\\bahar\\Repositories\\llm-ta-aied26\\results\\flat_reasoning_alignment_analysis.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8669960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Other': {}, 'WCT': {}, 'GT': {}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  compare agents code with correct code\n",
    "#  find each agents code accuracy\n",
    "agents = ['Ava', 'Ben', 'Cam']\n",
    "human_codes = df['human_code'].unique()\n",
    "#\n",
    "Agent_code_dict = {human_code: {} for human_code in human_codes}\n",
    "Agent_code_dict\n",
    "# codes_df = results_df['codes'].apply(pd.Series)\n",
    "# results_df['agent_code_correct'] = results_df['agent_code'] == results_df['correct_code']\n",
    "# results_df['agent_code_correct'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a0af3a",
   "metadata": {},
   "source": [
    "## EXTRACT REASONINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db31dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Dict, Optional\n",
    "\n",
    "def parse_deepseek_r1_output(raw_output: str) -> Dict[str, Optional[str]]:\n",
    "    \"\"\"\n",
    "    Improved DeepSeek R1 parser for 2026.\n",
    "    Handles unclosed <think> tags and multiple blocks efficiently.\n",
    "    \"\"\"\n",
    "    # Pattern explanation: \n",
    "    # 1. Capture content inside <think>...</think> OR unclosed <think>...\n",
    "    # 2. Capture everything following the (optional) closing </think> tag\n",
    "    pattern = r\"<think>(.*?)(?:</think>)?(?:\\s*)(.*)\"\n",
    "    match = re.search(pattern, raw_output, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        thinking = match.group(1).strip()\n",
    "        answer = match.group(2).strip()\n",
    "    else:\n",
    "        # Fallback if no <think> tags are present\n",
    "        thinking = None\n",
    "        answer = raw_output.strip()\n",
    "\n",
    "    return {\n",
    "        'thinking': thinking if thinking else None,\n",
    "        'answer': answer if answer else None,\n",
    "        'raw': raw_output\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd87d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Discussion 1 - 3 rounds\n",
      "==================================================\n",
      "Text:\n",
      "After next period we should see if we can take the sleep mode like maybe make it longer Like it goes it shuts off like the battery saving thing\n",
      "\n",
      "Human Code:\n",
      "Other\n",
      "\n",
      "Final Code:\n",
      "WCT\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Round 1 | Votes: {'NONE': 1, 'GT': 1, 'WCT': 1}\n",
      "----------------------------------------\n",
      "\n",
      "  Agent Ava:\n",
      "    Code: NONE\n",
      "    Rationale: The text does not provide evidence of the teacher addressing the whole class, a group, or any students or talking to herself or a visitor in a non-distracting way. The text is silent or talking to herself or a visitor in a non-distracting way.\n",
      "    Thinking: I'm sorry, I can't help with that.\n",
      "</think>\n",
      "\n",
      "{\"CAD-code\":\"NONE\",\"rationale\":\"The text does not provide evidence of the teacher addressing the whole class, a group, or any students or talking to herself or a visitor in a non-distracting way. The text is silent or talking to herself or a visitor in a non-distracting way.\"}\n",
      "\n",
      "  Agent Ben:\n",
      "    Code: GT\n",
      "    Rationale: The teacher is addressing a group of students, discussing a technical feature related to sleep mode, which falls under GT's role of addressing a group or student in a group.\n",
      "    Thinking: The text is: \"<text_to_code>\"\n",
      "\n",
      "I need to determine the CAD-code based on the text. The text is about the teacher's action after the next period, which seems to involve the class discussing a specific method or feature. The mention of \"sleep mode\" and \"battery saving thing\" suggests the teacher is discussing a technical detail or feature. The action described (\"make it longer\") implies the teacher is suggesting to extend the sleep mode, possibly for better battery life or performance.\n",
      "\n",
      "Looking at the context, the teacher is addressing a group of students, possibly the class, discussing a technical feature. The mention of \"sleep mode\" might be related to a device or software feature. The action of extending it suggests a change or improvement. \n",
      "\n",
      "The text doesn't specify the CAD-code, but based on the context, it's likely that the teacher is talking to a group (like GT) about a specific feature or action. The mention of \"sleep mode\" and \"battery saving thing\" points to a technical discussion, which would be GT's role.\n",
      "\n",
      "So, the CAD-code is GT because the teacher is addressing a group (the class) discussing a technical feature. The action is about extending the sleep mode, which is a group action. So, it fits under GT's role.\n",
      "\n",
      "The rationale should support this by citing the context and the action described. The text clearly states the teacher is addressing a group, which is GT, discussing a specific feature, so the CAD-code should be GT.\n",
      "</think>\n",
      "\n",
      "{\"CAD-code\":\"GT\",\"rationale\":\"The teacher is addressing a group of students, discussing a technical feature related to sleep mode, which falls under GT's role of addressing a group or student in a group.\"}\n",
      "\n",
      "  Agent Cam:\n",
      "    Code: WCT\n",
      "    Rationale: whole-class addressing\n",
      "    Thinking: {\"CAD-code\": \"WCT\", \"rationale\": \"whole-class addressing\"}\n",
      "\n",
      "----------------------------------------\n",
      "Round 2 | Votes: {'NONE': 2, 'WCT': 1}\n",
      "----------------------------------------\n",
      "\n",
      "  Agent Ava:\n",
      "    Code: NONE\n",
      "    Rationale: Ava is talking to herself or a visitor in a non-distracting way, which falls under NONE.\n",
      "    Thinking: I'm sorry, the text is silent or talking to herself or a visitor in a non-distracting way.\n",
      "\n",
      "Wait, the text says: \"<text_to_code>\"\n",
      "\n",
      "So, the text is talking about the sleep mode feature. It's not addressing any group or class. It's talking about the feature itself. So, Ava is talking about the feature, not the class. Therefore, she is not addressing the whole class, a group, or any students or talking to herself or a visitor in a non-distracting way. So, the CAD-code should be NONE.\n",
      "\n",
      "But wait, the text is silent or talking to herself or a visitor in a non-distracting way. So, Ava is talking to herself or a visitor, which is a non-distracting activity. So, according to the codebook, this would be classified as NONE.\n",
      "\n",
      "So, the JSON object should have CAD-code: NONE and the rationale explaining that Ava is talking to herself or a visitor in a non-distracting way, which falls under NONE.\n",
      "\n",
      "Yes, that's correct.\n",
      "</think>\n",
      "\n",
      "{\"CAD-code\":\"NONE\",\"rationale\":\"Ava is talking to herself or a visitor in a non-distracting way, which falls under NONE.\"}\n",
      "\n",
      "  Agent Ben:\n",
      "    Code: NONE\n",
      "    Rationale: The text is silent or talking to herself or a visitor in a non-distracting way. Ava's reasoning is correct.\n",
      "    Thinking: Wait, the text is silent or talking to herself or a visitor in a non-distracting way.\n",
      "\n",
      "I think Ava's reasoning is correct.\n",
      "</think>\n",
      "\n",
      "```json\n",
      "{\"CAD-code\":\"NONE\",\"rationale\":\"The text is silent or talking to herself or a visitor in a non-distracting way. Ava's reasoning is correct.\"\n",
      "}\n",
      "```\n",
      "\n",
      "  Agent Cam:\n",
      "    Code: WCT\n",
      "    Rationale: whole-class addressing\n",
      "    Thinking: {\"CAD-code\": \"WCT\", \"rationale\": \"whole-class addressing\"}\n",
      "\n",
      "----------------------------------------\n",
      "Round 3 | Votes: {'GT': 1, 'WCT': 2}\n",
      "----------------------------------------\n",
      "\n",
      "  Agent Ava:\n",
      "    Code: GT\n",
      "    Rationale: The teacher is addressing a specific group or student, discussing a sleep mode feature. This falls under GT as it's addressing a group or student in a group.\n",
      "    Thinking: I need to determine the correct CAD-code for the given text.\n",
      "\n",
      "The text is: \"<text_to_code>\"\n",
      "\n",
      "Looking at the text, it's talking about the teacher addressing a specific period or group. The text is discussing a sleep mode feature, which may involve a device or system, but it's not clear if it's a whole class or a group. The teacher is likely addressing a specific group or student, so the CAD-code should be GT.\n",
      "</think>\n",
      "\n",
      "{\"CAD-code\":\"GT\",\"rationale\":\"The teacher is addressing a specific group or student, discussing a sleep mode feature. This falls under GT as it's addressing a group or student in a group.\"}\n",
      "\n",
      "  Agent Ben:\n",
      "    Code: WCT\n",
      "    Rationale: The teacher is addressing the entire class with 'Everybody'.\n",
      "    Thinking: {\"CAD-code\": \"WCT\", \"rationale\": \"The teacher is addressing the entire class with 'Everybody'.\"}\n",
      "\n",
      "Wait, the user is Ben, and the text is about the classroom. The user is Ben, and the text is about the classroom. The user is Ben, and the text is about the classroom. The user is Ben, and the text is about the classroom. The user is Ben, and the text is about the classroom. The user is Ben, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is a teacher, and the text is about the classroom.\n",
      "\n",
      "Ben is\n",
      "\n",
      "  Agent Cam:\n",
      "    Code: WCT\n",
      "    Rationale: whole-class addressing\n",
      "    Thinking: {\"CAD-code\": \"WCT\", \"rationale\": \"whole-class addressing\"}\n"
     ]
    }
   ],
   "source": [
    "    round_dicts = df['round_dicts'].apply(eval).tolist()\n",
    "\n",
    "    for i, rds in enumerate(round_dicts[:1], 1):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Discussion {i} - {len(rds)} rounds\")\n",
    "        print('='*50)\n",
    "        row_dict = df.loc[i-1]\n",
    "        print(f\"Text:\\n{row_dict['text_to_code']}\\n\")\n",
    "        print(f\"Human Code:\\n{row_dict['human_code']}\\n\")\n",
    "        print(f\"Final Code:\\n{row_dict['final_code']}\\n\")\n",
    "        text_to_code = row_dict['text_to_code']\n",
    "\n",
    "        for r in rds:\n",
    "            print(f\"\\n{'-'*40}\")\n",
    "            print(f\"Round {r['round_num']} | Votes: {r['votes']}\")\n",
    "            print('-'*40)\n",
    "            \n",
    "            for agent_resp in r['responses']:\n",
    "                agent = agent_resp['agent']\n",
    "                raw_output = agent_resp['raw']\n",
    "                print(f\"\\n  Agent {agent}:\")\n",
    "                print(f\"    Code: {agent_resp['code']}\")\n",
    "                print(f\"    Rationale: {agent_resp['rationale']}\")\n",
    "\n",
    "                # Remove text_to_code from raw_output for clarity\n",
    "                if isinstance(text_to_code, str):\n",
    "                    raw_output = raw_output.replace(text_to_code, '<text_to_code>').strip()\n",
    "\n",
    "                parsed = parse_deepseek_r1_output(raw_output)\n",
    "                agent_thinking = parsed['thinking'] if parsed['thinking'] else raw_output\n",
    "                agent_answer = parsed['answer'] if parsed['answer'] else \"None\"\n",
    "                print(f\"    Thinking: {agent_thinking}\")\n",
    "                # else:\n",
    "                # print(f\"    Thinking: None. raw output:\\n{raw_output}\")\n",
    "                # if parsed['answer']:\n",
    "                #     print(f\"    Answer: {parsed['answer']}\")\n",
    "    #     print(\"\\nSummary :\")\n",
    "    #     print(f\"Total Rounds: {(rd[0])}\")\n",
    "\n",
    "    #     print(f\"\\n{'='*50}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310d454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embedding(text: str) -> list:\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-ta-aied26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
